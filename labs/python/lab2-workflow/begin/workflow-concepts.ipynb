{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”„ Workflow Concepts - Python AI Workflows\n",
    "\n",
    "This notebook explains the key concepts of building AI workflows using Python.\n",
    "\n",
    "> ðŸ“ **Hands-on Exercises**: After reviewing these concepts, complete the exercises in [EXERCISES.md](EXERCISES.md).\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [What is a Workflow?](#1-what-is-a-workflow)\n",
    "2. [Core Building Blocks](#2-core-building-blocks)\n",
    "3. [Sequential Workflow](#3-sequential-workflow)\n",
    "4. [Concurrent Workflow](#4-concurrent-workflow)\n",
    "5. [Human-in-the-Loop Workflow](#5-human-in-the-loop-workflow)\n",
    "6. [Workflow Events](#6-workflow-events)\n",
    "7. [Best Practices](#7-best-practices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is a Workflow?\n",
    "\n",
    "A **Workflow** is a directed graph of **Executors** connected by **Edges**. Data flows through the workflow, being processed by each executor in sequence or in parallel.\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Executor  â”‚â”€â”€â”€â”€â–¶â”‚ Executor  â”‚â”€â”€â”€â”€â–¶â”‚ Executor  â”‚\n",
    "â”‚    A      â”‚     â”‚    B      â”‚     â”‚    C      â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "     â”‚                                    â”‚\n",
    "     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Edge â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Key Benefits\n",
    "\n",
    "| Benefit | Description |\n",
    "|---------|-------------|\n",
    "| **Composability** | Build complex workflows from simple, reusable components |\n",
    "| **AI Integration** | Seamlessly integrate AI agents into the workflow |\n",
    "| **Human Oversight** | Pause workflows to get human input or approval |\n",
    "| **Streaming** | Process events as they occur, not just at completion |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Install Required Packages\n",
    "\n",
    "Run the following cell to install the required packages for Workflows and Azure OpenAI integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Install required packages\n",
    "# Run this cell first to ensure all dependencies are installed\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = [\n",
    "    \"openai\",\n",
    "    \"azure-identity\",\n",
    "    \"python-dotenv\"\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "    \n",
    "print(\"âœ… All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration: Load environment variables\n",
    "# Set up your Azure OpenAI connection\n",
    "\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "def find_config_path(start_path: str) -> str:\n",
    "    \"\"\"Find the 'python' folder by traversing up from start_path.\"\"\"\n",
    "    current_dir = Path(start_path)\n",
    "    \n",
    "    while current_dir is not None:\n",
    "        if current_dir.name.lower() == \"python\":\n",
    "            return str(current_dir)\n",
    "        if current_dir.parent == current_dir:\n",
    "            break\n",
    "        current_dir = current_dir.parent\n",
    "    \n",
    "    # Fallback to start path if python folder not found\n",
    "    return start_path\n",
    "\n",
    "\n",
    "def load_env_file(env_path: str) -> dict:\n",
    "    \"\"\"Load environment variables from .env file (JSON format).\"\"\"\n",
    "    env_file = Path(env_path) / \".env\"\n",
    "    \n",
    "    if not env_file.exists():\n",
    "        return {}\n",
    "    \n",
    "    try:\n",
    "        with open(env_file, 'r') as f:\n",
    "            content = f.read()\n",
    "            env_vars = json.loads(content)\n",
    "            \n",
    "            # Set environment variables\n",
    "            for key, value in env_vars.items():\n",
    "                os.environ[key] = str(value)\n",
    "            \n",
    "            return env_vars\n",
    "    except json.JSONDecodeError:\n",
    "        # Fallback: try loading as standard dotenv format\n",
    "        load_dotenv(env_file, override=True)\n",
    "        return {}\n",
    "    except IOError as e:\n",
    "        print(f\"Warning: Failed to load .env file: {e}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "# Load environment variables from .env file in the python root folder\n",
    "config_path = find_config_path(os.getcwd())\n",
    "env_vars = load_env_file(config_path)\n",
    "if env_vars:\n",
    "    print(f\"âœ… Loaded {len(env_vars)} environment variables from: {config_path}/.env\")\n",
    "else:\n",
    "    # Fallback: try loading from current directory\n",
    "    load_dotenv()\n",
    "    print(\"âš ï¸ Loaded .env from current directory (fallback)\")\n",
    "\n",
    "# Check required configuration - AZURE_OPENAI takes priority\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\") or os.getenv(\"AZURE_AI_PROJECT_ENDPOINT\")\n",
    "deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\") or os.getenv(\"AZURE_AI_MODEL_DEPLOYMENT_NAME\", \"gpt-4o-mini\")\n",
    "\n",
    "if endpoint:\n",
    "    print(f\"âœ… Azure OpenAI Endpoint: {endpoint}\")\n",
    "    print(f\"âœ… Deployment Name: {deployment}\")\n",
    "else:\n",
    "    print(\"âš ï¸ Azure endpoint not set\")\n",
    "    print(\"Please set one of the following environment variables:\")\n",
    "    print(\"  - AZURE_AI_PROJECT_ENDPOINT or AZURE_OPENAI_ENDPOINT\")\n",
    "    print(\"And optionally:\")\n",
    "    print(\"  - AZURE_AI_MODEL_DEPLOYMENT_NAME or AZURE_OPENAI_DEPLOYMENT_NAME (default: gpt-4o-mini)\")\n",
    "    print(\"  - AZURE_OPENAI_API_KEY (for API key auth)\")\n",
    "\n",
    "# Check authentication method\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "tenant_id = os.getenv(\"AZURE_TENANT_ID\")\n",
    "client_id = os.getenv(\"AZURE_CLIENT_ID\")\n",
    "client_secret = os.getenv(\"AZURE_CLIENT_SECRET\")\n",
    "\n",
    "if api_key:\n",
    "    print(\"âœ… Authentication: API Key\")\n",
    "elif tenant_id and client_id and client_secret:\n",
    "    print(\"âœ… Authentication: Service Principal\")\n",
    "else:\n",
    "    print(\"âœ… Authentication: Azure CLI / DefaultAzureCredential\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Azure OpenAI Client\n",
    "# This demonstrates how to set up the client with different auth methods\n",
    "\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential, AzureCliCredential, ClientSecretCredential, get_bearer_token_provider\n",
    "\n",
    "# Get configuration - AZURE_OPENAI takes priority over AZURE_AI_PROJECT\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\") or os.getenv(\"AZURE_AI_MODEL_DEPLOYMENT_NAME\", \"gpt-4o-mini\")\n",
    "\n",
    "# Only fall back to Foundry endpoint if Azure OpenAI endpoint is not set\n",
    "if not endpoint:\n",
    "    endpoint = os.getenv(\"AZURE_AI_PROJECT_ENDPOINT\")\n",
    "    deployment = os.getenv(\"AZURE_AI_MODEL_DEPLOYMENT_NAME\", deployment)\n",
    "    print(\"âš ï¸ Using Azure AI Foundry endpoint (AZURE_AI_PROJECT_ENDPOINT)\")\n",
    "\n",
    "if not endpoint:\n",
    "    raise ValueError(\"Azure endpoint not set. Set AZURE_OPENAI_ENDPOINT environment variable.\")\n",
    "\n",
    "api_version = \"2024-02-15-preview\"\n",
    "\n",
    "# Use API Key if provided (standard Azure OpenAI)\n",
    "if api_key:\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=endpoint,\n",
    "        api_key=api_key,\n",
    "        api_version=api_version\n",
    "    )\n",
    "    print(f\"âœ… Created AzureOpenAI client with API Key auth\")\n",
    "    print(f\"   Endpoint: {endpoint}\")\n",
    "    print(f\"   Deployment: {deployment}\")\n",
    "else:\n",
    "    # Token-based auth (for Foundry endpoints or when no API key)\n",
    "    print(\"âš ï¸ No API key found, using token-based authentication\")\n",
    "    try:\n",
    "        credential = AzureCliCredential()\n",
    "        token_provider = get_bearer_token_provider(credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "        client = AzureOpenAI(\n",
    "            azure_endpoint=endpoint,\n",
    "            azure_ad_token_provider=token_provider,\n",
    "            api_version=api_version\n",
    "        )\n",
    "        print(\"âœ… Created AzureOpenAI client with Azure CLI auth\")\n",
    "    except Exception as e:\n",
    "        credential = DefaultAzureCredential()\n",
    "        token_provider = get_bearer_token_provider(credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "        client = AzureOpenAI(\n",
    "            azure_endpoint=endpoint,\n",
    "            azure_ad_token_provider=token_provider,\n",
    "            api_version=api_version\n",
    "        )\n",
    "        print(\"âœ… Created AzureOpenAI client with DefaultAzureCredential\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Check your configuration values\n",
    "import os\n",
    "\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\") or os.getenv(\"AZURE_AI_MODEL_DEPLOYMENT_NAME\", \"gpt-4o-mini\")\n",
    "\n",
    "print(\"=== Configuration Check ===\")\n",
    "print(f\"Endpoint: {endpoint}\")\n",
    "print(f\"API Key: {'*' * 10 + api_key[-4:] if api_key and len(api_key) > 4 else 'NOT SET'}\")\n",
    "print(f\"Deployment: {deployment}\")\n",
    "print()\n",
    "print(\"âš ï¸ If you get 'DeploymentNotFound', the deployment name doesn't exist in your Azure OpenAI resource.\")\n",
    "print(\"   Check Azure Portal > Your Azure OpenAI resource > Model deployments\")\n",
    "print(\"   Common deployment names: gpt-4o-mini, gpt-4o, gpt-35-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Support Ticket model\n",
    "# This is the common data model used across all workflow patterns\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "@dataclass\n",
    "class SupportTicket:\n",
    "    \"\"\"Represents a customer support ticket.\"\"\"\n",
    "    ticket_id: str\n",
    "    customer_name: str\n",
    "    subject: str\n",
    "    description: str\n",
    "    category: Optional[str] = None\n",
    "    priority: Optional[str] = None\n",
    "    status: str = \"Open\"\n",
    "\n",
    "# Example ticket\n",
    "example_ticket = SupportTicket(\n",
    "    ticket_id=\"TICKET-001\",\n",
    "    customer_name=\"John Smith\",\n",
    "    subject=\"Cannot access my account\",\n",
    "    description=\"I've been trying to log in for the past hour but keep getting an 'invalid credentials' error. I'm sure my password is correct.\"\n",
    ")\n",
    "\n",
    "print(\"âœ… SupportTicket model defined\")\n",
    "print()\n",
    "print(\"Example Ticket:\")\n",
    "print(f\"  ID: {example_ticket.ticket_id}\")\n",
    "print(f\"  Customer: {example_ticket.customer_name}\")\n",
    "print(f\"  Subject: {example_ticket.subject}\")\n",
    "print(f\"  Status: {example_ticket.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow Building Blocks - Executor Base Class\n",
    "# This is the foundation for all workflow patterns\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "\n",
    "@dataclass\n",
    "class WorkflowEvent:\n",
    "    \"\"\"Event emitted during workflow execution.\"\"\"\n",
    "    executor_id: str\n",
    "    data: Any\n",
    "\n",
    "class Executor:\n",
    "    \"\"\"Base class for workflow executors.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "    \n",
    "    async def execute(self, input_data: Any) -> tuple[Any, WorkflowEvent]:\n",
    "        \"\"\"Execute the function and return result with event.\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses must implement execute()\")\n",
    "\n",
    "print(\"âœ… Workflow base classes defined\")\n",
    "print()\n",
    "print(\"Building Blocks:\")\n",
    "print(\"  - WorkflowEvent: Tracks execution events\")\n",
    "print(\"  - Executor: Base class for workflow steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Azure OpenAI connection with a simple workflow\n",
    "# This verifies everything is working before the hands-on exercises\n",
    "\n",
    "async def test_ai_call():\n",
    "    \"\"\"Test a simple AI call.\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=deployment,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Say 'Hello from Workflow Lab!' in exactly 5 words.\"}\n",
    "        ],\n",
    "        max_tokens=50\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Run the test\n",
    "import asyncio\n",
    "result = await test_ai_call()\n",
    "\n",
    "print(\"Response from Azure OpenAI:\")\n",
    "print(f\"  {result}\")\n",
    "print()\n",
    "print(f\"âœ… Azure OpenAI connection successful!\")\n",
    "print(\"You're ready to start the hands-on exercises!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Workflow Concepts - Python\n",
    "\n",
    "This notebook explains the key concepts of building AI workflows using Python with Azure OpenAI.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [What is a Workflow?](#1-what-is-a-workflow)\n",
    "2. [Core Building Blocks](#2-core-building-blocks)\n",
    "3. [Sequential Workflow](#3-sequential-workflow)\n",
    "4. [Concurrent Workflow](#4-concurrent-workflow)\n",
    "5. [Human-in-the-Loop Workflow](#5-human-in-the-loop-workflow)\n",
    "6. [Best Practices](#6-best-practices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is a Workflow?\n",
    "\n",
    "A **Workflow** is a series of **Executors** connected in sequence or parallel. Data flows through the workflow, being processed by each executor.\n",
    "\n",
    "`\n",
    "          \n",
    " Executor   Executor   Executor  \n",
    "    A               B               C      \n",
    "          \n",
    "`\n",
    "\n",
    "### Key Benefits\n",
    "\n",
    "| Benefit | Description |\n",
    "|---------|-------------|\n",
    "| **Composability** | Build complex workflows from simple, reusable components |\n",
    "| **AI Integration** | Seamlessly integrate AI agents into the workflow |\n",
    "| **Human Oversight** | Pause workflows to get human input or approval |\n",
    "| **Async Support** | Leverage Python's asyncio for concurrent execution |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Core Building Blocks\n",
    "\n",
    "### 2.1 Executors\n",
    "\n",
    "An **Executor** is a unit of work in a workflow. It receives input, processes it, and returns output.\n",
    "\n",
    "```python\n",
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "\n",
    "@dataclass\n",
    "class WorkflowEvent:\n",
    "    \"\"\"Event emitted during workflow execution.\"\"\"\n",
    "    executor_id: str\n",
    "    data: Any\n",
    "\n",
    "\n",
    "class Executor:\n",
    "    \"\"\"Base class for workflow executors.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "    \n",
    "    async def execute(self, input_data: Any) -> tuple[Any, WorkflowEvent]:\n",
    "        \"\"\"Execute the function and return result with event.\"\"\"\n",
    "        raise NotImplementedError\n",
    "```\n",
    "\n",
    "### Example: Ticket Intake Executor\n",
    "\n",
    "```python\n",
    "class TicketIntakeExecutor(Executor):\n",
    "    \"\"\"Executor that handles ticket intake and validation.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"TicketIntake\")\n",
    "    \n",
    "    async def execute(self, ticket: SupportTicket) -> tuple[str, WorkflowEvent]:\n",
    "        if not ticket.subject or not ticket.description:\n",
    "            raise ValueError(\"Support ticket must have a subject and description.\")\n",
    "        \n",
    "        ticket_text = f\"\"\"\n",
    "Ticket ID: {ticket.ticket_id}\n",
    "Customer: {ticket.customer_name}\n",
    "Subject: {ticket.subject}\n",
    "Description: {ticket.description}\n",
    "\"\"\"\n",
    "        event = WorkflowEvent(executor_id=self.name, data=ticket_text)\n",
    "        return ticket_text, event\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 AI Agents\n",
    "\n",
    "Integrate AI models (like Azure OpenAI) into workflows:\n",
    "\n",
    "```python\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "class AICategorizationExecutor(Executor):\n",
    "    \"\"\"Executor that uses AI to categorize the ticket.\"\"\"\n",
    "    \n",
    "    def __init__(self, client: AzureOpenAI, deployment: str):\n",
    "        super().__init__(\"CategorizationAgent\")\n",
    "        self.client = client\n",
    "        self.deployment = deployment\n",
    "        self.instructions = \"\"\"\n",
    "You are a customer support ticket categorization specialist.\n",
    "Analyze the incoming support ticket and categorize it into:\n",
    "- BILLING: Payment issues, invoices, subscription\n",
    "- TECHNICAL: Software bugs, errors, how-to questions\n",
    "- GENERAL: Account inquiries, feedback\n",
    "\n",
    "Respond with JSON: {\"category\": \"CATEGORY\", \"priority\": \"HIGH|MEDIUM|LOW\"}\n",
    "\"\"\"\n",
    "    \n",
    "    async def execute(self, ticket_text: str) -> tuple[str, WorkflowEvent]:\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.deployment,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.instructions},\n",
    "                {\"role\": \"user\", \"content\": ticket_text}\n",
    "            ]\n",
    "        )\n",
    "        result = response.choices[0].message.content\n",
    "        event = WorkflowEvent(executor_id=self.name, data=result)\n",
    "        return result, event\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Azure OpenAI Client Factory\n",
    "\n",
    "Support multiple authentication methods:\n",
    "\n",
    "```python\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import AzureCliCredential, DefaultAzureCredential\n",
    "\n",
    "def create_chat_client() -> AzureOpenAI:\n",
    "    \"\"\"Create Azure OpenAI client with multiple authentication options.\"\"\"\n",
    "    endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    if not endpoint:\n",
    "        raise ValueError(\"AZURE_OPENAI_ENDPOINT environment variable is required\")\n",
    "    \n",
    "    api_key = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "    \n",
    "    if api_key:\n",
    "        # Use API key authentication\n",
    "        return AzureOpenAI(\n",
    "            azure_endpoint=endpoint,\n",
    "            api_key=api_key,\n",
    "            api_version=\"2024-02-15-preview\"\n",
    "        )\n",
    "    else:\n",
    "        # Use Azure credential (CLI, Managed Identity, or Service Principal)\n",
    "        try:\n",
    "            credential = AzureCliCredential()\n",
    "            token = credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
    "        except Exception:\n",
    "            credential = DefaultAzureCredential()\n",
    "            token = credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
    "        \n",
    "        return AzureOpenAI(\n",
    "            azure_endpoint=endpoint,\n",
    "            api_key=token.token,\n",
    "            api_version=\"2024-02-15-preview\"\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sequential Workflow\n",
    "\n",
    "A **Sequential Workflow** processes data through a linear pipeline where each step depends on the previous one.\n",
    "\n",
    "### Architecture\n",
    "\n",
    "```\n",
    "            \n",
    "   Ticket      Categorization      Response           Final     \n",
    "   Intake           AI Agent               AI Agent              Response   \n",
    "            \n",
    "```\n",
    "\n",
    "### Implementation\n",
    "\n",
    "```python\n",
    "class SequentialWorkflow:\n",
    "    \"\"\"A workflow that executes steps sequentially.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.steps: list[Executor] = []\n",
    "    \n",
    "    def add_step(self, executor: Executor) -> \"SequentialWorkflow\":\n",
    "        \"\"\"Add a step to the workflow.\"\"\"\n",
    "        self.steps.append(executor)\n",
    "        return self\n",
    "    \n",
    "    async def run(self, input_data: Any) -> list[WorkflowEvent]:\n",
    "        \"\"\"Execute the workflow and return all events.\"\"\"\n",
    "        events = []\n",
    "        current_data = input_data\n",
    "        \n",
    "        for executor in self.steps:\n",
    "            current_data, event = await executor.execute(current_data)\n",
    "            events.append(event)\n",
    "        \n",
    "        return events\n",
    "```\n",
    "\n",
    "### Usage Example\n",
    "\n",
    "```python\n",
    "# Create executors\n",
    "ticket_intake = TicketIntakeExecutor()\n",
    "categorization_agent = AICategorizationExecutor(client, deployment)\n",
    "response_agent = AIResponseExecutor(client, deployment)\n",
    "\n",
    "# Build the sequential workflow\n",
    "workflow = SequentialWorkflow()\n",
    "workflow.add_step(ticket_intake)\n",
    "workflow.add_step(categorization_agent)\n",
    "workflow.add_step(response_agent)\n",
    "\n",
    "# Execute\n",
    "events = await workflow.run(sample_ticket)\n",
    "```\n",
    "\n",
    "### Use Cases\n",
    "\n",
    "- **Document Processing**: Parse  Extract  Summarize  Store\n",
    "- **Order Processing**: Validate  Calculate  Confirm  Fulfill\n",
    "- **Support Tickets**: Intake  Categorize  Respond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Concurrent Workflow\n",
    "\n",
    "A **Concurrent Workflow** distributes work to multiple executors simultaneously and aggregates results.\n",
    "\n",
    "### Architecture\n",
    "\n",
    "``\n",
    "                         \n",
    "                      Billing Expert      \n",
    "                 \n",
    "   Customer                                     Combined      \n",
    "   Question                      Response      \n",
    "      Technical Expert         \n",
    "                         \n",
    "                                                                \n",
    "        Fan-Out  Fan-In \n",
    "``\n",
    "\n",
    "### Implementation\n",
    "\n",
    "```python\n",
    "import asyncio\n",
    "\n",
    "class AIAgent:\n",
    "    \"\"\"An AI agent with a specific expertise.\"\"\"\n",
    "    \n",
    "    def __init__(self, client: AzureOpenAI, deployment: str, name: str, instructions: str):\n",
    "        self.client = client\n",
    "        self.deployment = deployment\n",
    "        self.name = name\n",
    "        self.instructions = instructions\n",
    "    \n",
    "    async def answer(self, question: str) -> str:\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.deployment,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.instructions},\n",
    "                {\"role\": \"user\", \"content\": question}\n",
    "            ],\n",
    "            max_tokens=200\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "\n",
    "class ConcurrentWorkflow:\n",
    "    \"\"\"A workflow that executes agents concurrently (fan-out/fan-in pattern).\"\"\"\n",
    "    \n",
    "    def __init__(self, agents: list[AIAgent]):\n",
    "        self.agents = agents\n",
    "    \n",
    "    async def run(self, question: str) -> dict[str, str]:\n",
    "        async def run_agent(agent: AIAgent) -> tuple[str, str]:\n",
    "            result = await agent.answer(question)\n",
    "            return agent.name, result\n",
    "        \n",
    "        # Fan-out: run all agents concurrently\n",
    "        tasks = [run_agent(agent) for agent in self.agents]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        \n",
    "        # Fan-in: collect results\n",
    "        return dict(results)\n",
    "```\n",
    "\n",
    "### Usage Example\n",
    "\n",
    "```python\n",
    "# Create specialized agents\n",
    "billing_expert = AIAgent(client, deployment, \"BillingExpert\",\n",
    "    \"You are an expert in billing and subscription matters.\")\n",
    "\n",
    "technical_expert = AIAgent(client, deployment, \"TechnicalExpert\",\n",
    "    \"You are an expert in technical support and troubleshooting.\")\n",
    "\n",
    "# Create and run workflow\n",
    "workflow = ConcurrentWorkflow([billing_expert, technical_expert])\n",
    "results = await workflow.run(\"My subscription was charged twice and the app crashes.\")\n",
    "\n",
    "for name, response in results.items():\n",
    "    print(f\"[{name}]: {response}\")\n",
    "```\n",
    "\n",
    "### Use Cases\n",
    "\n",
    "- **Multi-Expert Analysis**: Get perspectives from multiple specialists\n",
    "- **Parallel Processing**: Process multiple items simultaneously\n",
    "- **Consensus Building**: Aggregate opinions from multiple AI agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Human-in-the-Loop Workflow\n",
    "\n",
    "A **Human-in-the-Loop Workflow** pauses execution to get human input, approval, or oversight.\n",
    "\n",
    "### Architecture\n",
    "\n",
    "```\n",
    "            \n",
    "   Ticket       AI Draft      Human Review        Finalize   \n",
    "   Intake            Agent            (Supervisor)            Response   \n",
    "            \n",
    "                                               \n",
    "                                               \n",
    "                                      \n",
    "                                        Supervisor  \n",
    "                                        - Approve   \n",
    "                                        - Edit      \n",
    "                                        - Escalate  \n",
    "                                      \n",
    "```\n",
    "\n",
    "### Key Components\n",
    "\n",
    "```python\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Callable\n",
    "\n",
    "class ReviewAction(Enum):\n",
    "    APPROVE = \"Approve\"\n",
    "    EDIT = \"Edit\"\n",
    "    ESCALATE = \"Escalate\"\n",
    "\n",
    "@dataclass\n",
    "class SupervisorReviewRequest:\n",
    "    \"\"\"Request sent to supervisor for review.\"\"\"\n",
    "    ticket_id: str\n",
    "    category: str\n",
    "    priority: str\n",
    "    draft_response: str\n",
    "\n",
    "@dataclass\n",
    "class SupervisorDecision:\n",
    "    \"\"\"Supervisor's decision after reviewing the draft.\"\"\"\n",
    "    action: ReviewAction\n",
    "    modified_response: Optional[str]\n",
    "    notes: str\n",
    "```\n",
    "\n",
    "### Implementation\n",
    "\n",
    "```python\n",
    "class HumanInTheLoopWorkflow:\n",
    "    \"\"\"A workflow that pauses for human review/approval.\"\"\"\n",
    "    \n",
    "    def __init__(self, client: AzureOpenAI, deployment: str):\n",
    "        self.ticket_intake = TicketIntakeExecutor()\n",
    "        self.draft_agent = AIDraftExecutor(client, deployment)\n",
    "        self.current_ticket: Optional[SupportTicket] = None\n",
    "    \n",
    "    async def run(self, ticket: SupportTicket, input_handler: Callable) -> str:\n",
    "        \"\"\"Run the workflow with human review.\"\"\"\n",
    "        self.current_ticket = ticket\n",
    "        \n",
    "        # Step 1: Ticket Intake\n",
    "        ticket_text, _ = await self.ticket_intake.execute(ticket)\n",
    "        \n",
    "        # Step 2: AI Draft Generation\n",
    "        draft_response, _ = await self.draft_agent.execute(ticket_text)\n",
    "        \n",
    "        # Step 3: Create review request\n",
    "        review_request = SupervisorReviewRequest(\n",
    "            ticket_id=ticket.ticket_id,\n",
    "            category=self._determine_category(ticket.subject),\n",
    "            priority=ticket.priority.value,\n",
    "            draft_response=draft_response\n",
    "        )\n",
    "        \n",
    "        # Step 4: PAUSE - Get human supervisor decision\n",
    "        decision = await input_handler(review_request)\n",
    "        \n",
    "        # Step 5: Finalize based on decision\n",
    "        return self._finalize(decision)\n",
    "```\n",
    "\n",
    "### Console Input Handler\n",
    "\n",
    "```python\n",
    "async def console_supervisor_handler(review_request: SupervisorReviewRequest) -> SupervisorDecision:\n",
    "    print(f\"Ticket: {review_request.ticket_id}\")\n",
    "    print(f\"AI Draft: {review_request.draft_response}\")\n",
    "    print(\"[1] Approve [2] Edit [3] Escalate\")\n",
    "    \n",
    "    choice = input(\"Enter choice (1-3): \")\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        return SupervisorDecision(action=ReviewAction.APPROVE, modified_response=None, notes=\"Approved\")\n",
    "    elif choice == \"2\":\n",
    "        modified = input(\"Enter modified response: \")\n",
    "        return SupervisorDecision(action=ReviewAction.EDIT, modified_response=modified, notes=\"Modified\")\n",
    "    else:\n",
    "        reason = input(\"Enter escalation reason: \")\n",
    "        return SupervisorDecision(action=ReviewAction.ESCALATE, modified_response=None, notes=reason)\n",
    "```\n",
    "\n",
    "### Use Cases\n",
    "\n",
    "- **Content Approval**: AI drafts, human approves before publishing\n",
    "- **Financial Decisions**: AI recommends, human authorizes large transactions\n",
    "- **Customer Escalation**: AI handles routine, human handles exceptions\n",
    "- **Quality Control**: AI processes, human spot-checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Best Practices\n",
    "\n",
    "### 6.1 Executor Design\n",
    "\n",
    "- **Single Responsibility**: Each executor should do one thing well\n",
    "- **Stateless When Possible**: Avoid storing state in executors\n",
    "- **Clear Naming**: Use descriptive names that indicate the executor's purpose\n",
    "- **Type Hints**: Use Python type hints for better code clarity\n",
    "\n",
    "### 6.2 AI Agent Instructions\n",
    "\n",
    "```python\n",
    "#  Good: Specific, structured output\n",
    "instructions = \"\"\"\n",
    "Categorize tickets into: BILLING, TECHNICAL, GENERAL\n",
    "Output JSON: {\"category\": \"CATEGORY\", \"confidence\": 0.0-1.0}\n",
    "Be concise. Only output the JSON.\n",
    "\"\"\"\n",
    "\n",
    "#  Bad: Vague, unstructured\n",
    "instructions = \"Help with customer support\"\n",
    "```\n",
    "\n",
    "### 6.3 Error Handling\n",
    "\n",
    "```python\n",
    "try:\n",
    "    events = await workflow.run(sample_ticket)\n",
    "except Exception as e:\n",
    "    print(f\"Workflow error: {e}\")\n",
    "    # Log, retry, or escalate\n",
    "```\n",
    "\n",
    "### 6.4 Configuration Management\n",
    "\n",
    "```python\n",
    "import os\n",
    "\n",
    "# Support multiple auth methods via environment variables\n",
    "# 1. API Key: AZURE_OPENAI_API_KEY\n",
    "# 2. Azure CLI: (no env vars needed)\n",
    "# 3. Service Principal: AZURE_TENANT_ID, AZURE_CLIENT_ID, AZURE_CLIENT_SECRET\n",
    "\n",
    "endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "deployment = os.environ.get(\"AZURE_OPENAI_DEPLOYMENT_NAME\", \"gpt-4o-mini\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Pattern | When to Use | Key Methods |\n",
    "|---------|-------------|-------------|\n",
    "| **Sequential** | Linear processing pipeline | add_step(), un() |\n",
    "| **Concurrent** | Parallel processing, multi-expert | asyncio.gather() |\n",
    "| **Human-in-the-Loop** | Approval, oversight, exceptions | Input handler callback |\n",
    "\n",
    "### Quick Reference\n",
    "\n",
    "```python\n",
    "# Sequential workflow\n",
    "workflow = SequentialWorkflow()\n",
    "workflow.add_step(executor_a)\n",
    "workflow.add_step(executor_b)\n",
    "events = await workflow.run(input_data)\n",
    "\n",
    "# Concurrent workflow\n",
    "workflow = ConcurrentWorkflow([agent_a, agent_b])\n",
    "results = await workflow.run(question)\n",
    "\n",
    "# Human-in-the-loop workflow\n",
    "workflow = HumanInTheLoopWorkflow(client, deployment)\n",
    "result = await workflow.run(ticket, input_handler)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
