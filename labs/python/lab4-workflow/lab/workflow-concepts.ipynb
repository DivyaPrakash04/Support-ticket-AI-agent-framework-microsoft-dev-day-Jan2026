{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Install required packages\n",
    "# Run this cell first to ensure all dependencies are installed\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = [\n",
    "    \"openai\",\n",
    "    \"azure-identity\",\n",
    "    \"python-dotenv\"\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "    \n",
    "print(\"✅ All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration: Load environment variables\n",
    "# Set up your Azure OpenAI connection\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file (if present)\n",
    "load_dotenv()\n",
    "\n",
    "# Check required configuration\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\", \"gpt-4o-mini\")\n",
    "\n",
    "if endpoint:\n",
    "    print(f\"✅ Azure OpenAI Endpoint: {endpoint}\")\n",
    "    print(f\"✅ Deployment Name: {deployment}\")\n",
    "else:\n",
    "    print(\"⚠️ AZURE_OPENAI_ENDPOINT not set\")\n",
    "    print(\"Please set the following environment variable:\")\n",
    "    print(\"  - AZURE_OPENAI_ENDPOINT\")\n",
    "    print(\"And optionally:\")\n",
    "    print(\"  - AZURE_OPENAI_DEPLOYMENT_NAME (default: gpt-4o-mini)\")\n",
    "    print(\"  - AZURE_OPENAI_API_KEY (for API key auth)\")\n",
    "\n",
    "# Check authentication method\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "client_id = os.getenv(\"AZURE_CLIENT_ID\")\n",
    "\n",
    "if api_key:\n",
    "    print(\"✅ Authentication: API Key\")\n",
    "elif client_id:\n",
    "    print(\"✅ Authentication: Service Principal\")\n",
    "else:\n",
    "    print(\"✅ Authentication: Azure CLI / Managed Identity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Azure OpenAI Client\n",
    "# This demonstrates how to set up the client with different auth methods\n",
    "\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "# Get configuration\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\", \"gpt-4o-mini\")\n",
    "api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "\n",
    "if not endpoint:\n",
    "    raise ValueError(\"AZURE_OPENAI_ENDPOINT environment variable must be set\")\n",
    "\n",
    "# Create client based on authentication method\n",
    "if api_key:\n",
    "    # API Key authentication\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=endpoint,\n",
    "        api_key=api_key,\n",
    "        api_version=\"2024-10-21\"\n",
    "    )\n",
    "    print(\"✅ Created AzureOpenAI client with API Key auth\")\n",
    "else:\n",
    "    # Token-based authentication (Service Principal, Managed Identity, or Azure CLI)\n",
    "    credential = DefaultAzureCredential()\n",
    "    token_provider = get_bearer_token_provider(\n",
    "        credential, \n",
    "        \"https://cognitiveservices.azure.com/.default\"\n",
    "    )\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=endpoint,\n",
    "        azure_ad_token_provider=token_provider,\n",
    "        api_version=\"2024-10-21\"\n",
    "    )\n",
    "    print(\"✅ Created AzureOpenAI client with token-based auth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Support Ticket model\n",
    "# This is the common data model used across all workflow patterns\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "@dataclass\n",
    "class SupportTicket:\n",
    "    \"\"\"Represents a customer support ticket.\"\"\"\n",
    "    ticket_id: str\n",
    "    customer_name: str\n",
    "    subject: str\n",
    "    description: str\n",
    "    category: Optional[str] = None\n",
    "    priority: Optional[str] = None\n",
    "    status: str = \"Open\"\n",
    "\n",
    "# Example ticket\n",
    "example_ticket = SupportTicket(\n",
    "    ticket_id=\"TICKET-001\",\n",
    "    customer_name=\"John Smith\",\n",
    "    subject=\"Cannot access my account\",\n",
    "    description=\"I've been trying to log in for the past hour but keep getting an 'invalid credentials' error. I'm sure my password is correct.\"\n",
    ")\n",
    "\n",
    "print(\"✅ SupportTicket model defined\")\n",
    "print()\n",
    "print(\"Example Ticket:\")\n",
    "print(f\"  ID: {example_ticket.ticket_id}\")\n",
    "print(f\"  Customer: {example_ticket.customer_name}\")\n",
    "print(f\"  Subject: {example_ticket.subject}\")\n",
    "print(f\"  Status: {example_ticket.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow Building Blocks - Executor Base Class\n",
    "# This is the foundation for all workflow patterns\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "\n",
    "@dataclass\n",
    "class WorkflowEvent:\n",
    "    \"\"\"Event emitted during workflow execution.\"\"\"\n",
    "    executor_id: str\n",
    "    data: Any\n",
    "\n",
    "class Executor:\n",
    "    \"\"\"Base class for workflow executors.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "    \n",
    "    async def execute(self, input_data: Any) -> tuple[Any, WorkflowEvent]:\n",
    "        \"\"\"Execute the function and return result with event.\"\"\"\n",
    "        raise NotImplementedError(\"Subclasses must implement execute()\")\n",
    "\n",
    "print(\"✅ Workflow base classes defined\")\n",
    "print()\n",
    "print(\"Building Blocks:\")\n",
    "print(\"  - WorkflowEvent: Tracks execution events\")\n",
    "print(\"  - Executor: Base class for workflow steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Azure OpenAI connection with a simple workflow\n",
    "# This verifies everything is working before the hands-on exercises\n",
    "\n",
    "async def test_ai_call():\n",
    "    \"\"\"Test a simple AI call.\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=deployment,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Say 'Hello from Workflow Lab!' in exactly 5 words.\"}\n",
    "        ],\n",
    "        max_tokens=50\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Run the test\n",
    "import asyncio\n",
    "result = await test_ai_call()\n",
    "\n",
    "print(\"Response from Azure OpenAI:\")\n",
    "print(f\"  {result}\")\n",
    "print()\n",
    "print(f\"✅ Azure OpenAI connection successful!\")\n",
    "print(\"You're ready to start the hands-on exercises!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Workflow Concepts - Python\n",
    "\n",
    "This notebook explains the key concepts of building AI workflows using Python with Azure OpenAI.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [What is a Workflow?](#1-what-is-a-workflow)\n",
    "2. [Core Building Blocks](#2-core-building-blocks)\n",
    "3. [Sequential Workflow](#3-sequential-workflow)\n",
    "4. [Concurrent Workflow](#4-concurrent-workflow)\n",
    "5. [Human-in-the-Loop Workflow](#5-human-in-the-loop-workflow)\n",
    "6. [Best Practices](#6-best-practices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is a Workflow?\n",
    "\n",
    "A **Workflow** is a series of **Executors** connected in sequence or parallel. Data flows through the workflow, being processed by each executor.\n",
    "\n",
    "`\n",
    "          \n",
    " Executor   Executor   Executor  \n",
    "    A               B               C      \n",
    "          \n",
    "`\n",
    "\n",
    "### Key Benefits\n",
    "\n",
    "| Benefit | Description |\n",
    "|---------|-------------|\n",
    "| **Composability** | Build complex workflows from simple, reusable components |\n",
    "| **AI Integration** | Seamlessly integrate AI agents into the workflow |\n",
    "| **Human Oversight** | Pause workflows to get human input or approval |\n",
    "| **Async Support** | Leverage Python's asyncio for concurrent execution |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Core Building Blocks\n",
    "\n",
    "### 2.1 Executors\n",
    "\n",
    "An **Executor** is a unit of work in a workflow. It receives input, processes it, and returns output.\n",
    "\n",
    "`python\n",
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "\n",
    "@dataclass\n",
    "class WorkflowEvent:\n",
    "    \"\"\"Event emitted during workflow execution.\"\"\"\n",
    "    executor_id: str\n",
    "    data: Any\n",
    "\n",
    "\n",
    "class Executor:\n",
    "    \"\"\"Base class for workflow executors.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "    \n",
    "    async def execute(self, input_data: Any) -> tuple[Any, WorkflowEvent]:\n",
    "        \"\"\"Execute the function and return result with event.\"\"\"\n",
    "        raise NotImplementedError\n",
    "`\n",
    "\n",
    "### Example: Ticket Intake Executor\n",
    "\n",
    "`python\n",
    "class TicketIntakeExecutor(Executor):\n",
    "    \"\"\"Executor that handles ticket intake and validation.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(\"TicketIntake\")\n",
    "    \n",
    "    async def execute(self, ticket: SupportTicket) -> tuple[str, WorkflowEvent]:\n",
    "        if not ticket.subject or not ticket.description:\n",
    "            raise ValueError(\"Support ticket must have a subject and description.\")\n",
    "        \n",
    "        ticket_text = f\"\"\"\n",
    "Ticket ID: {ticket.ticket_id}\n",
    "Customer: {ticket.customer_name}\n",
    "Subject: {ticket.subject}\n",
    "Description: {ticket.description}\n",
    "\"\"\"\n",
    "        event = WorkflowEvent(executor_id=self.name, data=ticket_text)\n",
    "        return ticket_text, event\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 AI Agents\n",
    "\n",
    "Integrate AI models (like Azure OpenAI) into workflows:\n",
    "\n",
    "`python\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "class AICategorizationExecutor(Executor):\n",
    "    \"\"\"Executor that uses AI to categorize the ticket.\"\"\"\n",
    "    \n",
    "    def __init__(self, client: AzureOpenAI, deployment: str):\n",
    "        super().__init__(\"CategorizationAgent\")\n",
    "        self.client = client\n",
    "        self.deployment = deployment\n",
    "        self.instructions = \"\"\"\n",
    "You are a customer support ticket categorization specialist.\n",
    "Analyze the incoming support ticket and categorize it into:\n",
    "- BILLING: Payment issues, invoices, subscription\n",
    "- TECHNICAL: Software bugs, errors, how-to questions\n",
    "- GENERAL: Account inquiries, feedback\n",
    "\n",
    "Respond with JSON: {\"category\": \"CATEGORY\", \"priority\": \"HIGH|MEDIUM|LOW\"}\n",
    "\"\"\"\n",
    "    \n",
    "    async def execute(self, ticket_text: str) -> tuple[str, WorkflowEvent]:\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.deployment,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.instructions},\n",
    "                {\"role\": \"user\", \"content\": ticket_text}\n",
    "            ]\n",
    "        )\n",
    "        result = response.choices[0].message.content\n",
    "        event = WorkflowEvent(executor_id=self.name, data=result)\n",
    "        return result, event\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Azure OpenAI Client Factory\n",
    "\n",
    "Support multiple authentication methods:\n",
    "\n",
    "`python\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import AzureCliCredential, DefaultAzureCredential\n",
    "\n",
    "def create_chat_client() -> AzureOpenAI:\n",
    "    \"\"\"Create Azure OpenAI client with multiple authentication options.\"\"\"\n",
    "    endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    if not endpoint:\n",
    "        raise ValueError(\"AZURE_OPENAI_ENDPOINT environment variable is required\")\n",
    "    \n",
    "    api_key = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "    \n",
    "    if api_key:\n",
    "        # Use API key authentication\n",
    "        return AzureOpenAI(\n",
    "            azure_endpoint=endpoint,\n",
    "            api_key=api_key,\n",
    "            api_version=\"2024-02-15-preview\"\n",
    "        )\n",
    "    else:\n",
    "        # Use Azure credential (CLI, Managed Identity, or Service Principal)\n",
    "        try:\n",
    "            credential = AzureCliCredential()\n",
    "            token = credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
    "        except Exception:\n",
    "            credential = DefaultAzureCredential()\n",
    "            token = credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
    "        \n",
    "        return AzureOpenAI(\n",
    "            azure_endpoint=endpoint,\n",
    "            api_key=token.token,\n",
    "            api_version=\"2024-02-15-preview\"\n",
    "        )\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sequential Workflow\n",
    "\n",
    "A **Sequential Workflow** processes data through a linear pipeline where each step depends on the previous one.\n",
    "\n",
    "### Architecture\n",
    "\n",
    "`\n",
    "            \n",
    "   Ticket      Categorization      Response           Final     \n",
    "   Intake           AI Agent               AI Agent              Response   \n",
    "            \n",
    "`\n",
    "\n",
    "### Implementation\n",
    "\n",
    "`python\n",
    "class SequentialWorkflow:\n",
    "    \"\"\"A workflow that executes steps sequentially.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.steps: list[Executor] = []\n",
    "    \n",
    "    def add_step(self, executor: Executor) -> \"SequentialWorkflow\":\n",
    "        \"\"\"Add a step to the workflow.\"\"\"\n",
    "        self.steps.append(executor)\n",
    "        return self\n",
    "    \n",
    "    async def run(self, input_data: Any) -> list[WorkflowEvent]:\n",
    "        \"\"\"Execute the workflow and return all events.\"\"\"\n",
    "        events = []\n",
    "        current_data = input_data\n",
    "        \n",
    "        for executor in self.steps:\n",
    "            current_data, event = await executor.execute(current_data)\n",
    "            events.append(event)\n",
    "        \n",
    "        return events\n",
    "`\n",
    "\n",
    "### Usage Example\n",
    "\n",
    "`python\n",
    "# Create executors\n",
    "ticket_intake = TicketIntakeExecutor()\n",
    "categorization_agent = AICategorizationExecutor(client, deployment)\n",
    "response_agent = AIResponseExecutor(client, deployment)\n",
    "\n",
    "# Build the sequential workflow\n",
    "workflow = SequentialWorkflow()\n",
    "workflow.add_step(ticket_intake)\n",
    "workflow.add_step(categorization_agent)\n",
    "workflow.add_step(response_agent)\n",
    "\n",
    "# Execute\n",
    "events = await workflow.run(sample_ticket)\n",
    "`\n",
    "\n",
    "### Use Cases\n",
    "\n",
    "- **Document Processing**: Parse  Extract  Summarize  Store\n",
    "- **Order Processing**: Validate  Calculate  Confirm  Fulfill\n",
    "- **Support Tickets**: Intake  Categorize  Respond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Concurrent Workflow\n",
    "\n",
    "A **Concurrent Workflow** distributes work to multiple executors simultaneously and aggregates results.\n",
    "\n",
    "### Architecture\n",
    "\n",
    "`\n",
    "                         \n",
    "                      Billing Expert      \n",
    "                 \n",
    "   Customer                                     Combined      \n",
    "   Question                      Response      \n",
    "      Technical Expert         \n",
    "                         \n",
    "                                                                \n",
    "        Fan-Out  Fan-In \n",
    "`\n",
    "\n",
    "### Implementation\n",
    "\n",
    "`python\n",
    "import asyncio\n",
    "\n",
    "class AIAgent:\n",
    "    \"\"\"An AI agent with a specific expertise.\"\"\"\n",
    "    \n",
    "    def __init__(self, client: AzureOpenAI, deployment: str, name: str, instructions: str):\n",
    "        self.client = client\n",
    "        self.deployment = deployment\n",
    "        self.name = name\n",
    "        self.instructions = instructions\n",
    "    \n",
    "    async def answer(self, question: str) -> str:\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.deployment,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.instructions},\n",
    "                {\"role\": \"user\", \"content\": question}\n",
    "            ],\n",
    "            max_tokens=200\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "\n",
    "class ConcurrentWorkflow:\n",
    "    \"\"\"A workflow that executes agents concurrently (fan-out/fan-in pattern).\"\"\"\n",
    "    \n",
    "    def __init__(self, agents: list[AIAgent]):\n",
    "        self.agents = agents\n",
    "    \n",
    "    async def run(self, question: str) -> dict[str, str]:\n",
    "        async def run_agent(agent: AIAgent) -> tuple[str, str]:\n",
    "            result = await agent.answer(question)\n",
    "            return agent.name, result\n",
    "        \n",
    "        # Fan-out: run all agents concurrently\n",
    "        tasks = [run_agent(agent) for agent in self.agents]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        \n",
    "        # Fan-in: collect results\n",
    "        return dict(results)\n",
    "`\n",
    "\n",
    "### Usage Example\n",
    "\n",
    "`python\n",
    "# Create specialized agents\n",
    "billing_expert = AIAgent(client, deployment, \"BillingExpert\",\n",
    "    \"You are an expert in billing and subscription matters.\")\n",
    "\n",
    "technical_expert = AIAgent(client, deployment, \"TechnicalExpert\",\n",
    "    \"You are an expert in technical support and troubleshooting.\")\n",
    "\n",
    "# Create and run workflow\n",
    "workflow = ConcurrentWorkflow([billing_expert, technical_expert])\n",
    "results = await workflow.run(\"My subscription was charged twice and the app crashes.\")\n",
    "\n",
    "for name, response in results.items():\n",
    "    print(f\"[{name}]: {response}\")\n",
    "`\n",
    "\n",
    "### Use Cases\n",
    "\n",
    "- **Multi-Expert Analysis**: Get perspectives from multiple specialists\n",
    "- **Parallel Processing**: Process multiple items simultaneously\n",
    "- **Consensus Building**: Aggregate opinions from multiple AI agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Human-in-the-Loop Workflow\n",
    "\n",
    "A **Human-in-the-Loop Workflow** pauses execution to get human input, approval, or oversight.\n",
    "\n",
    "### Architecture\n",
    "\n",
    "`\n",
    "            \n",
    "   Ticket       AI Draft      Human Review        Finalize   \n",
    "   Intake            Agent            (Supervisor)            Response   \n",
    "            \n",
    "                                               \n",
    "                                               \n",
    "                                      \n",
    "                                        Supervisor  \n",
    "                                        - Approve   \n",
    "                                        - Edit      \n",
    "                                        - Escalate  \n",
    "                                      \n",
    "`\n",
    "\n",
    "### Key Components\n",
    "\n",
    "`python\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Callable\n",
    "\n",
    "class ReviewAction(Enum):\n",
    "    APPROVE = \"Approve\"\n",
    "    EDIT = \"Edit\"\n",
    "    ESCALATE = \"Escalate\"\n",
    "\n",
    "@dataclass\n",
    "class SupervisorReviewRequest:\n",
    "    \"\"\"Request sent to supervisor for review.\"\"\"\n",
    "    ticket_id: str\n",
    "    category: str\n",
    "    priority: str\n",
    "    draft_response: str\n",
    "\n",
    "@dataclass\n",
    "class SupervisorDecision:\n",
    "    \"\"\"Supervisor's decision after reviewing the draft.\"\"\"\n",
    "    action: ReviewAction\n",
    "    modified_response: Optional[str]\n",
    "    notes: str\n",
    "`\n",
    "\n",
    "### Implementation\n",
    "\n",
    "`python\n",
    "class HumanInTheLoopWorkflow:\n",
    "    \"\"\"A workflow that pauses for human review/approval.\"\"\"\n",
    "    \n",
    "    def __init__(self, client: AzureOpenAI, deployment: str):\n",
    "        self.ticket_intake = TicketIntakeExecutor()\n",
    "        self.draft_agent = AIDraftExecutor(client, deployment)\n",
    "        self.current_ticket: Optional[SupportTicket] = None\n",
    "    \n",
    "    async def run(self, ticket: SupportTicket, input_handler: Callable) -> str:\n",
    "        \"\"\"Run the workflow with human review.\"\"\"\n",
    "        self.current_ticket = ticket\n",
    "        \n",
    "        # Step 1: Ticket Intake\n",
    "        ticket_text, _ = await self.ticket_intake.execute(ticket)\n",
    "        \n",
    "        # Step 2: AI Draft Generation\n",
    "        draft_response, _ = await self.draft_agent.execute(ticket_text)\n",
    "        \n",
    "        # Step 3: Create review request\n",
    "        review_request = SupervisorReviewRequest(\n",
    "            ticket_id=ticket.ticket_id,\n",
    "            category=self._determine_category(ticket.subject),\n",
    "            priority=ticket.priority.value,\n",
    "            draft_response=draft_response\n",
    "        )\n",
    "        \n",
    "        # Step 4: PAUSE - Get human supervisor decision\n",
    "        decision = await input_handler(review_request)\n",
    "        \n",
    "        # Step 5: Finalize based on decision\n",
    "        return self._finalize(decision)\n",
    "`\n",
    "\n",
    "### Console Input Handler\n",
    "\n",
    "`python\n",
    "async def console_supervisor_handler(review_request: SupervisorReviewRequest) -> SupervisorDecision:\n",
    "    print(f\"Ticket: {review_request.ticket_id}\")\n",
    "    print(f\"AI Draft: {review_request.draft_response}\")\n",
    "    print(\"[1] Approve [2] Edit [3] Escalate\")\n",
    "    \n",
    "    choice = input(\"Enter choice (1-3): \")\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        return SupervisorDecision(action=ReviewAction.APPROVE, modified_response=None, notes=\"Approved\")\n",
    "    elif choice == \"2\":\n",
    "        modified = input(\"Enter modified response: \")\n",
    "        return SupervisorDecision(action=ReviewAction.EDIT, modified_response=modified, notes=\"Modified\")\n",
    "    else:\n",
    "        reason = input(\"Enter escalation reason: \")\n",
    "        return SupervisorDecision(action=ReviewAction.ESCALATE, modified_response=None, notes=reason)\n",
    "`\n",
    "\n",
    "### Use Cases\n",
    "\n",
    "- **Content Approval**: AI drafts, human approves before publishing\n",
    "- **Financial Decisions**: AI recommends, human authorizes large transactions\n",
    "- **Customer Escalation**: AI handles routine, human handles exceptions\n",
    "- **Quality Control**: AI processes, human spot-checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Best Practices\n",
    "\n",
    "### 6.1 Executor Design\n",
    "\n",
    "- **Single Responsibility**: Each executor should do one thing well\n",
    "- **Stateless When Possible**: Avoid storing state in executors\n",
    "- **Clear Naming**: Use descriptive names that indicate the executor's purpose\n",
    "- **Type Hints**: Use Python type hints for better code clarity\n",
    "\n",
    "### 6.2 AI Agent Instructions\n",
    "\n",
    "`python\n",
    "#  Good: Specific, structured output\n",
    "instructions = \"\"\"\n",
    "Categorize tickets into: BILLING, TECHNICAL, GENERAL\n",
    "Output JSON: {\"category\": \"CATEGORY\", \"confidence\": 0.0-1.0}\n",
    "Be concise. Only output the JSON.\n",
    "\"\"\"\n",
    "\n",
    "#  Bad: Vague, unstructured\n",
    "instructions = \"Help with customer support\"\n",
    "`\n",
    "\n",
    "### 6.3 Error Handling\n",
    "\n",
    "`python\n",
    "try:\n",
    "    events = await workflow.run(sample_ticket)\n",
    "except Exception as e:\n",
    "    print(f\"Workflow error: {e}\")\n",
    "    # Log, retry, or escalate\n",
    "`\n",
    "\n",
    "### 6.4 Configuration Management\n",
    "\n",
    "`python\n",
    "import os\n",
    "\n",
    "# Support multiple auth methods via environment variables\n",
    "# 1. API Key: AZURE_OPENAI_API_KEY\n",
    "# 2. Azure CLI: (no env vars needed)\n",
    "# 3. Service Principal: AZURE_TENANT_ID, AZURE_CLIENT_ID, AZURE_CLIENT_SECRET\n",
    "\n",
    "endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "deployment = os.environ.get(\"AZURE_OPENAI_DEPLOYMENT_NAME\", \"gpt-4o-mini\")\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Pattern | When to Use | Key Methods |\n",
    "|---------|-------------|-------------|\n",
    "| **Sequential** | Linear processing pipeline | add_step(), un() |\n",
    "| **Concurrent** | Parallel processing, multi-expert | asyncio.gather() |\n",
    "| **Human-in-the-Loop** | Approval, oversight, exceptions | Input handler callback |\n",
    "\n",
    "### Quick Reference\n",
    "\n",
    "`python\n",
    "# Sequential workflow\n",
    "workflow = SequentialWorkflow()\n",
    "workflow.add_step(executor_a)\n",
    "workflow.add_step(executor_b)\n",
    "events = await workflow.run(input_data)\n",
    "\n",
    "# Concurrent workflow\n",
    "workflow = ConcurrentWorkflow([agent_a, agent_b])\n",
    "results = await workflow.run(question)\n",
    "\n",
    "# Human-in-the-loop workflow\n",
    "workflow = HumanInTheLoopWorkflow(client, deployment)\n",
    "result = await workflow.run(ticket, input_handler)\n",
    "`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
