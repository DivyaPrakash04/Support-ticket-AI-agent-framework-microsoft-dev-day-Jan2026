{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5baa6b69",
   "metadata": {},
   "source": [
    "# Notebook 3: Advanced RAG\n",
    "\n",
    "In this notebook, you will be exploring how [AzureAISearchContextProvider](https://learn.microsoft.com/en-us/python/api/agent-framework-core/agent_framework.azure.azureaisearchcontextprovider?view=agent-framework-python-latest) performs better retrieval than just using the simple RAG approach.\n",
    "\n",
    "## Learning Objectives\n",
    "- Learn to use [AzureAISearchContextProvider](https://learn.microsoft.com/en-us/python/api/agent-framework-core/agent_framework.azure.azureaisearchcontextprovider?view=agent-framework-python-latest) to combine vector and keyword searches with semantic ranking.\n",
    "- Learn how to use the AzureAISearchContextProvider as a context_provider with a ChatAgent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9884ef59",
   "metadata": {},
   "source": [
    "### Setup the Module Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31e3d776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from agent_framework import ChatAgent\n",
    "from agent_framework.azure import AzureOpenAIChatClient, AzureAISearchContextProvider\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65847dfc",
   "metadata": {},
   "source": [
    "### Get the needed environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8a2f840",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "search_endpoint = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "search_key = os.getenv(\"AZURE_SEARCH_API_KEY\")\n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME\")\n",
    "project_endpoint = os.getenv(\"AZURE_AI_PROJECT_ENDPOINT\")\n",
    "model_deployment = os.getenv(\"AZURE_AI_MODEL_DEPLOYMENT_NAME\")\n",
    "embedding_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7de5a34",
   "metadata": {},
   "source": [
    "Define a method to get embeddings for the queries we are going to be asking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebdb738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EMBEDDING_DIMENSIONS = 1536 #3072 for 3-large\n",
    "\n",
    "async def get_embeddings(text: str) -> list[float]:\n",
    "    if not text or text.strip() == \"\":\n",
    "        # Return zero vector for empty text\n",
    "        return [0.0] * EMBEDDING_DIMENSIONS\n",
    "    \n",
    "    # Truncate text if too long (max ~8000 tokens for ada-002)\n",
    "    max_chars = 30000  # Approximate character limit\n",
    "    if len(text) > max_chars:\n",
    "        text = text[:max_chars]\n",
    "    \n",
    "    # Create a token provider that returns a fresh bearer token on each call\n",
    "    token_provider = get_bearer_token_provider(\n",
    "        DefaultAzureCredential(),\n",
    "        \"https://cognitiveservices.azure.com/.default\",\n",
    "    )\n",
    "\n",
    "    client = AzureOpenAI(\n",
    "        azure_ad_token_provider=token_provider,\n",
    "        api_version=\"2024-02-01\",\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = client.embeddings.create(\n",
    "            input=text,\n",
    "            model=embedding_deployment\n",
    "        )\n",
    "        return response.data[0].embedding\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating embedding: {e}\")\n",
    "        # Return zero vector on error\n",
    "        return [0.0] * EMBEDDING_DIMENSIONS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3f0dab",
   "metadata": {},
   "source": [
    "Initialize the AzureAISearchContextProvider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bff19008",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_provider = AzureAISearchContextProvider(\n",
    "        endpoint=search_endpoint,\n",
    "        index_name=index_name,\n",
    "        api_key=search_key,\n",
    "        mode=\"semantic\", \n",
    "        top_k=3,  # Retrieve top 3 most relevant documents\n",
    "        vector_field_name=\"BodyEmbeddings\",\n",
    "        embedding_function=get_embeddings\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b627b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample queries to demonstrate RAG\n",
    "USER_INPUTS = [\n",
    "    #\"What problems are there with Surface devices?\",\n",
    "    \"What sort of AWS problems have been reported?\",\n",
    "    #\"Are there any issues logged for Dell XPS laptops?\"\n",
    "    #\"Do we have more issues with MacBook Air computers or Dell XPS laptops?\",\n",
    "\t#\"What issues do we have with dell xps laptops?\",\n",
    "\t#\"What issues are for Dell XPS laptops and the user tried Win + Ctrl + Shift + B?\",\n",
    "\t#\"How many tickets were logged and Incidents for Human Resources and low priority?\",\n",
    "\t#\"Which Dell XPS issue does not mention Windows?\",\n",
    "    #\"What department had consultants with Login Issues?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e25f962",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ChatAgent(\n",
    "    chat_client=AzureOpenAIChatClient(credential=DefaultAzureCredential()),\n",
    "    name=\"SearchAgent\",\n",
    "    instructions=(\n",
    "        \"You are a helpful assistant. Use the provided context from the knowledge base to answer questions accurately.\"\n",
    "    ),\n",
    "    context_providers=[search_provider]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4258e3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Azure AI Agent with Search Context (Semantic Mode) ===\n",
      "\n",
      "User: What sort of AWS problems have been reported?\n",
      "Agent: The reported AWS problems include:\n",
      "\n",
      "1. An AWS service outage causing disruption and requiring a swift fix.\n",
      "2. Issues with deployment and infrastructure optimization using AWS Management Service, possibly due to misconfiguration or resource allocation challenges.\n",
      "3. Critical scalability and reliability problems in AWS infrastructure, including inconsistent elasticity in instance scaling and delays in deployment operations, impacting operational efficiency and customer satisfaction.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# Reduce logging verbosity for Azure Search\n",
    "logging.getLogger('azure.search').setLevel(logging.ERROR)\n",
    "\n",
    "print(\"=== Azure AI Agent with Search Context (Semantic Mode) ===\\n\")\n",
    "\n",
    "for user_input in USER_INPUTS:\n",
    "    print(f\"User: {user_input}\")\n",
    "    print(\"Agent: \", end=\"\", flush=True)\n",
    "\n",
    "    # Stream response\n",
    "    async for chunk in agent.run_stream(user_input):\n",
    "        if chunk.text:\n",
    "            print(chunk.text, end=\"\", flush=True)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aee0fe",
   "metadata": {},
   "source": [
    "Play around with the questions you ask. You'll find it does better than the simple RAG approach in Notebook 2.\n",
    "\n",
    "However, it still won't get \"How many tickets were logged and Incidents for Human Resources and low priority?\" correct."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
